{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d691a4a9",
   "metadata": {},
   "source": [
    "# CDAO SDK Demo: Multi-Platform ML Workflow Execution\n",
    "\n",
    "This notebook demonstrates how to use the CDAO SDK to create and execute ML workflows across multiple compute platforms through Flyte's plugin architecture.\n",
    "\n",
    "## What You'll Learn:\n",
    "- Setting up the CDAO SDK with pre-configured Flyte access\n",
    "- Defining tasks with platform-specific decorators\n",
    "- Creating workflows that span multiple compute environments\n",
    "- Monitoring execution across different platforms\n",
    "- Best practices for data science experimentation\n",
    "\n",
    "## Architecture Overview:\n",
    "- **Control Plane**: Flyte Admin & Propeller in AWS EKS\n",
    "- **Local Execution**: EKS pods for quick tasks\n",
    "- **GPU Workloads**: Codeweave platform for ML training\n",
    "- **Batch Processing**: AWS Batch for cost-effective long jobs\n",
    "- **Big Data**: EMR Spark for distributed analytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894aa080",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Install and Import CDAO SDK\n",
    "# The CDAO SDK comes pre-configured with access to the control plane\n",
    "\n",
    "!pip install cdao-sdk --quiet\n",
    "\n",
    "import cdao_sdk\n",
    "from cdao_sdk import task, workflow, gpu_task, batch_task, spark_task, cpu_task\n",
    "from cdao_sdk.types import FlyteFile, FlyteDirectory\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Dict, List\n",
    "import time\n",
    "\n",
    "print(\"‚úÖ CDAO SDK imported successfully\")\n",
    "print(f\"SDK Version: {cdao_sdk.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be81cfe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Configure SDK with Control Plane Access\n",
    "# The SDK is pre-configured with credentials and endpoints\n",
    "\n",
    "cdao_sdk.configure(\n",
    "    # Pre-configured control plane endpoints\n",
    "    admin_endpoint=\"https://flyte.your-domain.com\",\n",
    "    project=\"ml-experiments\",\n",
    "    domain=\"development\",\n",
    "    \n",
    "    # Authentication is handled automatically via CDAO credentials\n",
    "    auth_mode=\"corporate_sso\",\n",
    "    \n",
    "    # Default execution settings\n",
    "    default_image=\"ghcr.io/flyteorg/flytekit:py3.9-1.10.3\",\n",
    "    \n",
    "    # S3 storage configuration (pre-configured buckets)\n",
    "    storage_config={\n",
    "        \"metadata_bucket\": \"s3://education-eks-flyte-metadata-xxx\",\n",
    "        \"userdata_bucket\": \"s3://education-eks-flyte-userdata-xxx\",\n",
    "        \"workflow_bucket\": \"s3://bsingh-ml-workflows\"\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"‚úÖ CDAO SDK configured with control plane access\")\n",
    "print(\"üîó Connected to Flyte cluster via plugins\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb19af4",
   "metadata": {},
   "source": [
    "## Task Definitions with Platform Targeting\n",
    "\n",
    "The CDAO SDK provides decorators that automatically route tasks to the most appropriate compute platform based on resource requirements and cost optimization.\n",
    "\n",
    "### Available Decorators:\n",
    "- `@cpu_task`: Local EKS execution for quick tasks\n",
    "- `@gpu_task`: Codeweave platform for GPU-accelerated workloads\n",
    "- `@batch_task`: AWS Batch for cost-effective long-running jobs\n",
    "- `@spark_task`: EMR Spark for big data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6f3800",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Define Data Preprocessing Task (AWS Batch - Cost Optimized)\n",
    "\n",
    "@batch_task(\n",
    "    # Route to AWS Batch for cost optimization\n",
    "    platform=\"aws-batch\",\n",
    "    instance_type=\"c5.2xlarge\",\n",
    "    spot_instances=True,  # Use spot instances for cost savings\n",
    "    timeout_minutes=60,\n",
    "    requests={\"cpu\": \"2\", \"memory\": \"8Gi\"},\n",
    "    limits={\"cpu\": \"4\", \"memory\": \"16Gi\"}\n",
    ")\n",
    "def preprocess_credit_data(\n",
    "    raw_data_path: str,\n",
    "    cleaning_config: Dict[str, any]\n",
    ") -> FlyteFile:\n",
    "    \"\"\"\n",
    "    Preprocess credit scoring data on AWS Batch with spot instances.\n",
    "    This task handles large-scale data cleaning and feature engineering.\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "    \n",
    "    print(f\"üîÑ Processing data from: {raw_data_path}\")\n",
    "    print(f\"üìä Using AWS Batch with spot instances for cost optimization\")\n",
    "    \n",
    "    # Simulate data loading and processing\n",
    "    # In real scenario, this would load from S3\n",
    "    data = pd.read_csv(raw_data_path)\n",
    "    \n",
    "    # Data cleaning steps\n",
    "    data = data.dropna()\n",
    "    data = data.drop_duplicates()\n",
    "    \n",
    "    # Feature engineering\n",
    "    scaler = StandardScaler()\n",
    "    numeric_cols = data.select_dtypes(include=[np.number]).columns\n",
    "    data[numeric_cols] = scaler.fit_transform(data[numeric_cols])\n",
    "    \n",
    "    # Save processed data\n",
    "    output_path = \"/tmp/processed_data.parquet\"\n",
    "    data.to_parquet(output_path)\n",
    "    \n",
    "    print(f\"‚úÖ Data preprocessing completed. Output saved to S3.\")\n",
    "    return FlyteFile(path=output_path)\n",
    "\n",
    "print(\"‚úÖ Data preprocessing task defined for AWS Batch execution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12bc1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Define Feature Engineering Task (Local EKS - Quick Execution)\n",
    "\n",
    "@cpu_task(\n",
    "    # Route to local EKS for quick turnaround\n",
    "    platform=\"local-eks\",\n",
    "    requests={\"cpu\": \"1\", \"memory\": \"4Gi\"},\n",
    "    limits={\"cpu\": \"2\", \"memory\": \"8Gi\"},\n",
    "    timeout_minutes=30\n",
    ")\n",
    "def engineer_features(\n",
    "    processed_data: FlyteFile,\n",
    "    feature_config: Dict[str, any]\n",
    ") -> FlyteFile:\n",
    "    \"\"\"\n",
    "    Feature engineering task executed on local EKS for quick iteration.\n",
    "    Ideal for development and testing phases.\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from sklearn.preprocessing import PolynomialFeatures\n",
    "    \n",
    "    print(\"üîß Engineering features on local EKS cluster\")\n",
    "    print(\"‚ö° Quick execution for iterative development\")\n",
    "    \n",
    "    # Load processed data\n",
    "    data = pd.read_parquet(processed_data.path)\n",
    "    \n",
    "    # Create polynomial features\n",
    "    poly_features = PolynomialFeatures(degree=2, include_bias=False)\n",
    "    numeric_cols = data.select_dtypes(include=[np.number]).columns[:5]  # Limit for demo\n",
    "    poly_data = poly_features.fit_transform(data[numeric_cols])\n",
    "    \n",
    "    # Create feature names\n",
    "    feature_names = poly_features.get_feature_names_out(numeric_cols)\n",
    "    poly_df = pd.DataFrame(poly_data, columns=feature_names)\n",
    "    \n",
    "    # Combine with original data\n",
    "    final_data = pd.concat([data, poly_df], axis=1)\n",
    "    \n",
    "    # Save engineered features\n",
    "    output_path = \"/tmp/engineered_features.parquet\"\n",
    "    final_data.to_parquet(output_path)\n",
    "    \n",
    "    print(f\"‚úÖ Feature engineering completed. {len(feature_names)} new features created.\")\n",
    "    return FlyteFile(path=output_path)\n",
    "\n",
    "print(\"‚úÖ Feature engineering task defined for local EKS execution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a693ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Define Model Training Task (Codeweave GPU - ML Optimized)\n",
    "\n",
    "@gpu_task(\n",
    "    # Route to Codeweave for GPU-accelerated training\n",
    "    platform=\"codeweave\",\n",
    "    gpu_type=\"nvidia-tesla-v100\",\n",
    "    gpu_count=1,\n",
    "    requests={\"cpu\": \"4\", \"memory\": \"16Gi\", \"gpu\": \"1\"},\n",
    "    limits={\"cpu\": \"8\", \"memory\": \"32Gi\", \"gpu\": \"1\"},\n",
    "    timeout_minutes=180,\n",
    "    container_image=\"your-registry/ml-training:gpu-latest\"\n",
    ")\n",
    "def train_neural_network(\n",
    "    feature_data: FlyteFile,\n",
    "    model_config: Dict[str, any]\n",
    ") -> Dict[str, any]:\n",
    "    \"\"\"\n",
    "    Train a neural network model on Codeweave GPU infrastructure.\n",
    "    Optimized for deep learning workloads with GPU acceleration.\n",
    "    \"\"\"\n",
    "    print(\"üöÄ Training neural network on Codeweave GPU cluster\")\n",
    "    print(\"üíé Using V100 GPU for accelerated training\")\n",
    "    \n",
    "    import torch\n",
    "    import torch.nn as nn\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "    \n",
    "    # Load feature data\n",
    "    data = pd.read_parquet(feature_data.path)\n",
    "    \n",
    "    # Prepare training data\n",
    "    X = data.drop(['target'], axis=1).values  # Assuming 'target' column exists\n",
    "    y = data['target'].values\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "    \n",
    "    # Convert to PyTorch tensors and move to GPU\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    X_train_tensor = torch.FloatTensor(X_train).to(device)\n",
    "    y_train_tensor = torch.FloatTensor(y_train).to(device)\n",
    "    X_test_tensor = torch.FloatTensor(X_test).to(device)\n",
    "    \n",
    "    # Define neural network\n",
    "    class CreditScoringNet(nn.Module):\n",
    "        def __init__(self, input_size):\n",
    "            super(CreditScoringNet, self).__init__()\n",
    "            self.network = nn.Sequential(\n",
    "                nn.Linear(input_size, 256),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(0.3),\n",
    "                nn.Linear(256, 128),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(0.3),\n",
    "                nn.Linear(128, 64),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(64, 1),\n",
    "                nn.Sigmoid()\n",
    "            )\n",
    "        \n",
    "        def forward(self, x):\n",
    "            return self.network(x)\n",
    "    \n",
    "    # Initialize model and move to GPU\n",
    "    model = CreditScoringNet(X_train.shape[1]).to(device)\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=model_config.get('learning_rate', 0.001))\n",
    "    \n",
    "    # Training loop\n",
    "    epochs = model_config.get('epochs', 100)\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_train_tensor)\n",
    "        loss = criterion(outputs.squeeze(), y_train_tensor)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if epoch % 20 == 0:\n",
    "            print(f\"Epoch {epoch}/{epochs}, Loss: {loss.item():.4f}\")\n",
    "    \n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        test_outputs = model(X_test_tensor)\n",
    "        predictions = (test_outputs.squeeze() > 0.5).cpu().numpy()\n",
    "        test_probs = test_outputs.squeeze().cpu().numpy()\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    auc_score = roc_auc_score(y_test, test_probs)\n",
    "    \n",
    "    # Save model\n",
    "    model_path = \"/tmp/neural_network_model.pth\"\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    \n",
    "    results = {\n",
    "        \"model_path\": model_path,\n",
    "        \"accuracy\": float(accuracy),\n",
    "        \"auc_score\": float(auc_score),\n",
    "        \"training_completed\": True,\n",
    "        \"gpu_used\": str(device)\n",
    "    }\n",
    "    \n",
    "    print(f\"‚úÖ Neural network training completed on GPU\")\n",
    "    print(f\"üìä Accuracy: {accuracy:.4f}, AUC: {auc_score:.4f}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "print(\"‚úÖ Neural network training task defined for Codeweave GPU execution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ef0933",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Define Big Data Analytics Task (EMR Spark - Distributed Processing)\n",
    "\n",
    "@spark_task(\n",
    "    # Route to EMR Spark for big data processing\n",
    "    platform=\"emr-spark\",\n",
    "    cluster_size=\"medium\",  # 1 master + 3 workers\n",
    "    instance_type=\"r5.xlarge\",\n",
    "    spark_config={\n",
    "        \"spark.sql.adaptive.enabled\": \"true\",\n",
    "        \"spark.sql.adaptive.coalescePartitions.enabled\": \"true\"\n",
    "    },\n",
    "    timeout_minutes=120\n",
    ")\n",
    "def analyze_credit_patterns(\n",
    "    processed_data: FlyteFile,\n",
    "    analysis_config: Dict[str, any]\n",
    ") -> Dict[str, any]:\n",
    "    \"\"\"\n",
    "    Perform large-scale analytics on credit data using Spark on EMR.\n",
    "    Ideal for distributed computing and big data analysis.\n",
    "    \"\"\"\n",
    "    print(\"üìä Analyzing credit patterns on EMR Spark cluster\")\n",
    "    print(\"üîÑ Distributed processing for large datasets\")\n",
    "    \n",
    "    from pyspark.sql import SparkSession\n",
    "    from pyspark.sql.functions import col, avg, count, stddev, corr\n",
    "    from pyspark.ml.feature import VectorAssembler\n",
    "    from pyspark.ml.stat import Correlation\n",
    "    \n",
    "    # Initialize Spark session\n",
    "    spark = SparkSession.builder \\\n",
    "        .appName(\"CreditPatternAnalysis\") \\\n",
    "        .getOrCreate()\n",
    "    \n",
    "    # Load data into Spark DataFrame\n",
    "    df = spark.read.parquet(processed_data.path)\n",
    "    \n",
    "    print(f\"üìà Processing {df.count()} records across Spark cluster\")\n",
    "    \n",
    "    # Basic statistics\n",
    "    numeric_cols = [field.name for field in df.schema.fields \n",
    "                   if str(field.dataType) in ['DoubleType', 'IntegerType', 'FloatType']]\n",
    "    \n",
    "    stats_results = {}\n",
    "    \n",
    "    # Calculate correlation matrix for top features\n",
    "    vector_assembler = VectorAssembler(\n",
    "        inputCols=numeric_cols[:10],  # Limit for demo\n",
    "        outputCol=\"features\"\n",
    "    )\n",
    "    \n",
    "    df_vector = vector_assembler.transform(df)\n",
    "    correlation_matrix = Correlation.corr(df_vector, \"features\").head()\n",
    "    \n",
    "    # Risk pattern analysis\n",
    "    risk_patterns = df.groupBy(\"risk_category\") \\\n",
    "        .agg(\n",
    "            count(\"*\").alias(\"count\"),\n",
    "            avg(\"credit_score\").alias(\"avg_credit_score\"),\n",
    "            avg(\"income\").alias(\"avg_income\"),\n",
    "            stddev(\"credit_score\").alias(\"credit_score_std\")\n",
    "        ).collect()\n",
    "    \n",
    "    # Geographic analysis (if location data exists)\n",
    "    if \"state\" in df.columns:\n",
    "        geographic_analysis = df.groupBy(\"state\") \\\n",
    "            .agg(\n",
    "                count(\"*\").alias(\"applications\"),\n",
    "                avg(\"credit_score\").alias(\"avg_score\"),\n",
    "                (count(col(\"default_flag\") == 1) / count(\"*\")).alias(\"default_rate\")\n",
    "            ).orderBy(col(\"default_rate\").desc()).collect()\n",
    "    \n",
    "    # Time-based patterns (if date columns exist)\n",
    "    temporal_patterns = {}\n",
    "    if \"application_date\" in df.columns:\n",
    "        temporal_patterns = df.groupBy(\"month\", \"year\") \\\n",
    "            .agg(\n",
    "                count(\"*\").alias(\"applications\"),\n",
    "                avg(\"credit_score\").alias(\"avg_score\")\n",
    "            ).collect()\n",
    "    \n",
    "    # Stop Spark session\n",
    "    spark.stop()\n",
    "    \n",
    "    results = {\n",
    "        \"total_records\": df.count(),\n",
    "        \"correlation_analysis\": \"completed\",\n",
    "        \"risk_patterns\": len(risk_patterns),\n",
    "        \"geographic_analysis\": \"completed\" if \"state\" in df.columns else \"skipped\",\n",
    "        \"temporal_analysis\": \"completed\" if \"application_date\" in df.columns else \"skipped\",\n",
    "        \"processing_time\": \"optimized_with_spark\"\n",
    "    }\n",
    "    \n",
    "    print(\"‚úÖ Big data analytics completed on EMR Spark\")\n",
    "    print(f\"üéØ Analyzed patterns across {df.count()} records\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "print(\"‚úÖ Big data analytics task defined for EMR Spark execution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30903a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Define Model Evaluation Task (Local EKS - Quick Results)\n",
    "\n",
    "@cpu_task(\n",
    "    platform=\"local-eks\",\n",
    "    requests={\"cpu\": \"1\", \"memory\": \"2Gi\"},\n",
    "    limits={\"cpu\": \"2\", \"memory\": \"4Gi\"},\n",
    "    timeout_minutes=15\n",
    ")\n",
    "def evaluate_model_performance(\n",
    "    model_results: Dict[str, any],\n",
    "    analytics_results: Dict[str, any],\n",
    "    evaluation_config: Dict[str, any]\n",
    ") -> Dict[str, any]:\n",
    "    \"\"\"\n",
    "    Evaluate model performance and generate business insights.\n",
    "    Quick execution on local EKS for immediate feedback.\n",
    "    \"\"\"\n",
    "    print(\"üìä Evaluating model performance on local EKS\")\n",
    "    print(\"‚ö° Quick evaluation for immediate insights\")\n",
    "    \n",
    "    import numpy as np\n",
    "    from datetime import datetime\n",
    "    \n",
    "    # Extract model metrics\n",
    "    model_accuracy = model_results.get(\"accuracy\", 0.0)\n",
    "    model_auc = model_results.get(\"auc_score\", 0.0)\n",
    "    \n",
    "    # Calculate business impact\n",
    "    baseline_accuracy = 0.75  # Assume current business baseline\n",
    "    improvement = model_accuracy - baseline_accuracy\n",
    "    \n",
    "    # Business metrics\n",
    "    annual_applications = 100000  # Example business volume\n",
    "    cost_per_false_positive = 500  # Cost of approving bad credit\n",
    "    revenue_per_true_positive = 50  # Revenue from good credit approval\n",
    "    \n",
    "    # Calculate ROI\n",
    "    annual_improvement = annual_applications * improvement\n",
    "    annual_cost_savings = annual_improvement * cost_per_false_positive * 0.1  # 10% FP reduction\n",
    "    annual_revenue_increase = annual_improvement * revenue_per_true_positive * 0.05  # 5% TP increase\n",
    "    \n",
    "    total_annual_impact = annual_cost_savings + annual_revenue_increase\n",
    "    \n",
    "    # Model readiness assessment\n",
    "    readiness_score = 0\n",
    "    if model_accuracy > 0.80:\n",
    "        readiness_score += 30\n",
    "    if model_auc > 0.85:\n",
    "        readiness_score += 30\n",
    "    if improvement > 0.05:\n",
    "        readiness_score += 40\n",
    "    \n",
    "    readiness_level = \"Not Ready\"\n",
    "    if readiness_score >= 70:\n",
    "        readiness_level = \"Production Ready\"\n",
    "    elif readiness_score >= 50:\n",
    "        readiness_level = \"Needs Improvement\"\n",
    "    else:\n",
    "        readiness_level = \"Requires Significant Work\"\n",
    "    \n",
    "    evaluation_results = {\n",
    "        \"model_performance\": {\n",
    "            \"accuracy\": model_accuracy,\n",
    "            \"auc_score\": model_auc,\n",
    "            \"improvement_over_baseline\": improvement\n",
    "        },\n",
    "        \"business_impact\": {\n",
    "            \"annual_cost_savings\": annual_cost_savings,\n",
    "            \"annual_revenue_increase\": annual_revenue_increase,\n",
    "            \"total_annual_impact\": total_annual_impact\n",
    "        },\n",
    "        \"readiness_assessment\": {\n",
    "            \"score\": readiness_score,\n",
    "            \"level\": readiness_level,\n",
    "            \"recommendation\": \"Deploy to production\" if readiness_score >= 70 else \"Continue development\"\n",
    "        },\n",
    "        \"evaluation_timestamp\": datetime.now().isoformat(),\n",
    "        \"platform_utilization\": {\n",
    "            \"preprocessing_platform\": \"AWS Batch (spot instances)\",\n",
    "            \"training_platform\": \"Codeweave GPU\",\n",
    "            \"analytics_platform\": \"EMR Spark\",\n",
    "            \"evaluation_platform\": \"Local EKS\"\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    print(f\"‚úÖ Model evaluation completed\")\n",
    "    print(f\"üéØ Accuracy: {model_accuracy:.3f}, AUC: {model_auc:.3f}\")\n",
    "    print(f\"üí∞ Estimated annual impact: ${total_annual_impact:,.2f}\")\n",
    "    print(f\"üö¶ Readiness: {readiness_level}\")\n",
    "    \n",
    "    return evaluation_results\n",
    "\n",
    "print(\"‚úÖ Model evaluation task defined for local EKS execution\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979e01b6",
   "metadata": {},
   "source": [
    "## Workflow Definition\n",
    "\n",
    "Now we'll create a comprehensive ML workflow that orchestrates all tasks across multiple compute platforms, leveraging Flyte's plugin architecture for optimal resource utilization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f2921a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Create Multi-Platform ML Workflow\n",
    "\n",
    "@workflow\n",
    "def comprehensive_ml_pipeline(\n",
    "    raw_data_path: str = \"s3://bsingh-ml-workflows/credit_data/raw/credit_data.csv\",\n",
    "    cleaning_config: Dict[str, any] = {\"remove_outliers\": True, \"fill_na\": \"median\"},\n",
    "    feature_config: Dict[str, any] = {\"polynomial_degree\": 2, \"interaction_terms\": True},\n",
    "    model_config: Dict[str, any] = {\"epochs\": 100, \"learning_rate\": 0.001, \"batch_size\": 256},\n",
    "    analysis_config: Dict[str, any] = {\"correlation_threshold\": 0.8, \"risk_segments\": 5},\n",
    "    evaluation_config: Dict[str, any] = {\"baseline_accuracy\": 0.75, \"target_auc\": 0.85}\n",
    ") -> Dict[str, any]:\n",
    "    \"\"\"\n",
    "    Comprehensive ML pipeline that demonstrates multi-platform execution:\n",
    "    \n",
    "    1. Data Preprocessing (AWS Batch - cost optimized)\n",
    "    2. Feature Engineering (Local EKS - quick iteration)  \n",
    "    3. Model Training (Codeweave GPU - ML optimized)\n",
    "    4. Big Data Analytics (EMR Spark - distributed processing)\n",
    "    5. Model Evaluation (Local EKS - immediate results)\n",
    "    \n",
    "    Each task is automatically routed to the optimal compute platform\n",
    "    based on resource requirements and cost considerations.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"üöÄ Starting comprehensive ML pipeline across multiple platforms\")\n",
    "    \n",
    "    # Step 1: Data Preprocessing on AWS Batch (cost-effective for large data)\n",
    "    print(\"üìä Step 1: Data preprocessing on AWS Batch with spot instances\")\n",
    "    processed_data = preprocess_credit_data(\n",
    "        raw_data_path=raw_data_path,\n",
    "        cleaning_config=cleaning_config\n",
    "    )\n",
    "    \n",
    "    # Step 2: Feature Engineering on Local EKS (quick turnaround for development)\n",
    "    print(\"üîß Step 2: Feature engineering on local EKS cluster\")\n",
    "    engineered_features = engineer_features(\n",
    "        processed_data=processed_data,\n",
    "        feature_config=feature_config\n",
    "    )\n",
    "    \n",
    "    # Step 3: Model Training on Codeweave GPU (specialized ML hardware)\n",
    "    print(\"üß† Step 3: Neural network training on Codeweave GPU infrastructure\")\n",
    "    model_results = train_neural_network(\n",
    "        feature_data=engineered_features,\n",
    "        model_config=model_config\n",
    "    )\n",
    "    \n",
    "    # Step 4: Big Data Analytics on EMR Spark (distributed analytics)\n",
    "    print(\"üìà Step 4: Pattern analysis on EMR Spark cluster\")\n",
    "    analytics_results = analyze_credit_patterns(\n",
    "        processed_data=processed_data,\n",
    "        analysis_config=analysis_config\n",
    "    )\n",
    "    \n",
    "    # Step 5: Model Evaluation on Local EKS (immediate business insights)\n",
    "    print(\"üéØ Step 5: Model evaluation and business impact assessment\")\n",
    "    final_evaluation = evaluate_model_performance(\n",
    "        model_results=model_results,\n",
    "        analytics_results=analytics_results,\n",
    "        evaluation_config=evaluation_config\n",
    "    )\n",
    "    \n",
    "    print(\"‚úÖ Multi-platform ML pipeline completed successfully\")\n",
    "    \n",
    "    return final_evaluation\n",
    "\n",
    "print(\"‚úÖ Comprehensive ML workflow defined\")\n",
    "print(\"üîÑ Workflow will execute across 4 different compute platforms\")\n",
    "print(\"üí° Each task automatically routed to optimal platform by Flyte Propeller\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e45a851",
   "metadata": {},
   "source": [
    "## Workflow Execution and Monitoring\n",
    "\n",
    "Now we'll execute the workflow and demonstrate real-time monitoring capabilities of the CDAO SDK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69af15c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Execute Workflow with Real-time Monitoring\n",
    "\n",
    "print(\"üöÄ Executing multi-platform ML workflow via CDAO SDK\")\n",
    "print(\"üì° Submitting to Flyte control plane for orchestration\")\n",
    "\n",
    "# Execute the workflow\n",
    "execution = cdao_sdk.run(\n",
    "    workflow=comprehensive_ml_pipeline,\n",
    "    inputs={\n",
    "        \"raw_data_path\": \"s3://bsingh-ml-workflows/credit_data/sample_data.csv\",\n",
    "        \"model_config\": {\n",
    "            \"epochs\": 50,  # Reduced for demo\n",
    "            \"learning_rate\": 0.001,\n",
    "            \"batch_size\": 128\n",
    "        },\n",
    "        \"analysis_config\": {\n",
    "            \"correlation_threshold\": 0.75,\n",
    "            \"risk_segments\": 3\n",
    "        }\n",
    "    },\n",
    "    execution_name=f\"multi_platform_ml_demo_{int(time.time())}\",\n",
    "    wait_for_completion=False  # Enable real-time monitoring\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Workflow submitted successfully\")\n",
    "print(f\"üÜî Execution ID: {execution.id}\")\n",
    "print(f\"üîó Execution URL: {execution.console_url}\")\n",
    "print(f\"üìä Status: {execution.status}\")\n",
    "\n",
    "# Store execution for monitoring\n",
    "workflow_execution = execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc9f30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: Real-time Monitoring Dashboard\n",
    "\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def create_monitoring_dashboard(execution):\n",
    "    \"\"\"Create a real-time monitoring dashboard for the workflow execution\"\"\"\n",
    "    \n",
    "    # Platform mapping for visual representation\n",
    "    platform_colors = {\n",
    "        'aws-batch': '#ff9900',      # AWS Orange\n",
    "        'local-eks': '#2ecc71',      # Green\n",
    "        'codeweave': '#e74c3c',      # Red\n",
    "        'emr-spark': '#f39c12',      # Orange\n",
    "    }\n",
    "    \n",
    "    # Get current execution status\n",
    "    current_status = cdao_sdk.get_execution_status(execution.id)\n",
    "    \n",
    "    print(\"üñ•Ô∏è  CDAO SDK - Multi-Platform Execution Monitor\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"üÜî Execution ID: {execution.id}\")\n",
    "    print(f\"üìä Overall Status: {current_status.phase}\")\n",
    "    print(f\"‚è±Ô∏è  Started: {current_status.created_at}\")\n",
    "    print(f\"‚è∞ Duration: {current_status.duration}\")\n",
    "    print(\"\")\n",
    "    \n",
    "    # Task status breakdown\n",
    "    print(\"üìã Task Execution Status by Platform:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    task_statuses = current_status.task_executions\n",
    "    \n",
    "    for task_name, task_info in task_statuses.items():\n",
    "        platform = task_info.get('platform', 'unknown')\n",
    "        status = task_info.get('status', 'unknown')\n",
    "        \n",
    "        status_icon = {\n",
    "            'QUEUED': '‚è≥',\n",
    "            'RUNNING': 'üîÑ',\n",
    "            'SUCCEEDED': '‚úÖ',\n",
    "            'FAILED': '‚ùå',\n",
    "            'ABORTED': 'üõë'\n",
    "        }.get(status, '‚ùì')\n",
    "        \n",
    "        print(f\"{status_icon} {task_name}\")\n",
    "        print(f\"   Platform: {platform}\")\n",
    "        print(f\"   Status: {status}\")\n",
    "        if 'duration' in task_info:\n",
    "            print(f\"   Duration: {task_info['duration']}\")\n",
    "        if 'cost_estimate' in task_info:\n",
    "            print(f\"   Est. Cost: ${task_info['cost_estimate']:.4f}\")\n",
    "        print(\"\")\n",
    "    \n",
    "    # Resource utilization summary\n",
    "    print(\"üí∞ Platform Cost Optimization:\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    total_cost = 0\n",
    "    platform_usage = {}\n",
    "    \n",
    "    for task_name, task_info in task_statuses.items():\n",
    "        platform = task_info.get('platform', 'local-eks')\n",
    "        cost = task_info.get('cost_estimate', 0.01)\n",
    "        total_cost += cost\n",
    "        \n",
    "        if platform not in platform_usage:\n",
    "            platform_usage[platform] = {'tasks': 0, 'cost': 0}\n",
    "        \n",
    "        platform_usage[platform]['tasks'] += 1\n",
    "        platform_usage[platform]['cost'] += cost\n",
    "    \n",
    "    for platform, usage in platform_usage.items():\n",
    "        cost_per_task = usage['cost'] / usage['tasks'] if usage['tasks'] > 0 else 0\n",
    "        print(f\"üî∏ {platform}: {usage['tasks']} tasks, ${usage['cost']:.4f} (${cost_per_task:.4f}/task)\")\n",
    "    \n",
    "    print(f\"\\nüí∏ Total Estimated Cost: ${total_cost:.4f}\")\n",
    "    \n",
    "    # Progress visualization\n",
    "    completed_tasks = sum(1 for t in task_statuses.values() if t.get('status') == 'SUCCEEDED')\n",
    "    total_tasks = len(task_statuses)\n",
    "    progress = (completed_tasks / total_tasks) * 100 if total_tasks > 0 else 0\n",
    "    \n",
    "    print(f\"\\nüìà Progress: {completed_tasks}/{total_tasks} tasks completed ({progress:.1f}%)\")\n",
    "    print(f\"{'‚ñà' * int(progress/5)}{'‚ñë' * (20-int(progress/5))} {progress:.1f}%\")\n",
    "    \n",
    "    return current_status.phase\n",
    "\n",
    "# Start monitoring\n",
    "print(\"üîÑ Starting real-time monitoring...\")\n",
    "print(\"üí° This will show task execution across different platforms\")\n",
    "\n",
    "try:\n",
    "    # Monitor for a few iterations (in real scenario, this would run until completion)\n",
    "    for i in range(5):\n",
    "        clear_output(wait=True)\n",
    "        \n",
    "        status = create_monitoring_dashboard(workflow_execution)\n",
    "        \n",
    "        if status in ['SUCCEEDED', 'FAILED', 'ABORTED']:\n",
    "            break\n",
    "            \n",
    "        print(f\"\\n‚è±Ô∏è  Monitoring iteration {i+1}/5 (updating every 30 seconds)\")\n",
    "        print(\"üîÑ Workflow executing across multiple compute platforms...\")\n",
    "        \n",
    "        time.sleep(5)  # Reduced for demo (normally 30 seconds)\n",
    "        \n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\n‚èπÔ∏è  Monitoring stopped by user\")\n",
    "\n",
    "print(\"\\n‚úÖ Monitoring session completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99accc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 11: Retrieve and Analyze Results\n",
    "\n",
    "print(\"üìä Retrieving workflow execution results...\")\n",
    "\n",
    "# Get final results (this would normally wait for completion)\n",
    "try:\n",
    "    # In real scenario, this would retrieve actual results\n",
    "    final_results = cdao_sdk.get_execution_results(workflow_execution.id)\n",
    "    \n",
    "    print(\"‚úÖ Workflow execution completed successfully!\")\n",
    "    print(\"\\nüìà Final Results Summary:\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Model Performance Results\n",
    "    if 'model_performance' in final_results:\n",
    "        perf = final_results['model_performance']\n",
    "        print(f\"üß† Model Performance:\")\n",
    "        print(f\"   Accuracy: {perf.get('accuracy', 'N/A'):.3f}\")\n",
    "        print(f\"   AUC Score: {perf.get('auc_score', 'N/A'):.3f}\")\n",
    "        print(f\"   Improvement: {perf.get('improvement_over_baseline', 'N/A'):.3f}\")\n",
    "    \n",
    "    # Business Impact\n",
    "    if 'business_impact' in final_results:\n",
    "        impact = final_results['business_impact']\n",
    "        print(f\"\\nüí∞ Business Impact:\")\n",
    "        print(f\"   Annual Cost Savings: ${impact.get('annual_cost_savings', 0):,.2f}\")\n",
    "        print(f\"   Annual Revenue Increase: ${impact.get('annual_revenue_increase', 0):,.2f}\")\n",
    "        print(f\"   Total Annual Impact: ${impact.get('total_annual_impact', 0):,.2f}\")\n",
    "    \n",
    "    # Platform Utilization\n",
    "    if 'platform_utilization' in final_results:\n",
    "        platforms = final_results['platform_utilization']\n",
    "        print(f\"\\nüîß Platform Utilization:\")\n",
    "        for task, platform in platforms.items():\n",
    "            print(f\"   {task}: {platform}\")\n",
    "    \n",
    "    # Readiness Assessment\n",
    "    if 'readiness_assessment' in final_results:\n",
    "        readiness = final_results['readiness_assessment']\n",
    "        print(f\"\\nüö¶ Production Readiness:\")\n",
    "        print(f\"   Score: {readiness.get('score', 'N/A')}/100\")\n",
    "        print(f\"   Level: {readiness.get('level', 'N/A')}\")\n",
    "        print(f\"   Recommendation: {readiness.get('recommendation', 'N/A')}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è  Results not yet available: {e}\")\n",
    "    print(\"üí° In a real scenario, you would wait for workflow completion\")\n",
    "    \n",
    "    # Show example results structure\n",
    "    print(\"\\nüìã Example Results Structure:\")\n",
    "    example_results = {\n",
    "        \"model_performance\": {\n",
    "            \"accuracy\": 0.847,\n",
    "            \"auc_score\": 0.892,\n",
    "            \"improvement_over_baseline\": 0.097\n",
    "        },\n",
    "        \"business_impact\": {\n",
    "            \"annual_cost_savings\": 485000.00,\n",
    "            \"annual_revenue_increase\": 125000.00,\n",
    "            \"total_annual_impact\": 610000.00\n",
    "        },\n",
    "        \"platform_utilization\": {\n",
    "            \"preprocessing\": \"AWS Batch (spot instances)\",\n",
    "            \"training\": \"Codeweave GPU (V100)\",\n",
    "            \"analytics\": \"EMR Spark (3-node cluster)\",\n",
    "            \"evaluation\": \"Local EKS\"\n",
    "        },\n",
    "        \"readiness_assessment\": {\n",
    "            \"score\": 85,\n",
    "            \"level\": \"Production Ready\",\n",
    "            \"recommendation\": \"Deploy to production\"\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    import json\n",
    "    print(json.dumps(example_results, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9331804",
   "metadata": {},
   "source": [
    "## Advanced Features and Best Practices\n",
    "\n",
    "### Key Benefits of CDAO SDK + Multi-Platform Architecture:\n",
    "\n",
    "1. **Cost Optimization**: Automatic routing to most cost-effective platform\n",
    "2. **Performance**: GPU acceleration for ML, distributed processing for big data\n",
    "3. **Developer Experience**: Simple decorators hide complex infrastructure\n",
    "4. **Scalability**: Automatic scaling across multiple compute environments\n",
    "5. **Monitoring**: Real-time visibility across all platforms\n",
    "\n",
    "### Best Practices:\n",
    "\n",
    "- Use `@cpu_task` for quick development and testing\n",
    "- Use `@gpu_task` for ML training and inference workloads\n",
    "- Use `@batch_task` with spot instances for cost-sensitive long jobs\n",
    "- Use `@spark_task` for big data analytics and distributed processing\n",
    "- Monitor costs and optimize platform selection based on workload patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7094b01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 12: Advanced SDK Features and Scheduling\n",
    "\n",
    "print(\"üîß Demonstrating advanced CDAO SDK features...\")\n",
    "\n",
    "# Schedule workflow for regular execution\n",
    "scheduled_execution = cdao_sdk.schedule_workflow(\n",
    "    workflow=comprehensive_ml_pipeline,\n",
    "    schedule=\"0 2 * * 1\",  # Every Monday at 2 AM\n",
    "    inputs={\n",
    "        \"raw_data_path\": \"s3://bsingh-ml-workflows/credit_data/weekly_batch.csv\",\n",
    "        \"model_config\": {\"epochs\": 200, \"learning_rate\": 0.0005}\n",
    "    },\n",
    "    schedule_name=\"weekly_model_retrain\",\n",
    "    enabled=True\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Scheduled weekly retraining: {scheduled_execution.schedule_id}\")\n",
    "\n",
    "# Create development vs production configurations\n",
    "dev_config = cdao_sdk.create_environment_config(\n",
    "    name=\"development\",\n",
    "    default_resources={\"cpu\": \"500m\", \"memory\": \"1Gi\"},\n",
    "    cost_optimization=True,\n",
    "    use_spot_instances=True\n",
    ")\n",
    "\n",
    "prod_config = cdao_sdk.create_environment_config(\n",
    "    name=\"production\", \n",
    "    default_resources={\"cpu\": \"2\", \"memory\": \"4Gi\"},\n",
    "    cost_optimization=False,\n",
    "    use_spot_instances=False,\n",
    "    high_availability=True\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Environment configurations created\")\n",
    "\n",
    "# Workflow versioning and rollback\n",
    "version_info = cdao_sdk.create_workflow_version(\n",
    "    workflow=comprehensive_ml_pipeline,\n",
    "    version=\"v1.2.0\",\n",
    "    description=\"Added EMR Spark analytics and improved GPU training\",\n",
    "    changelog=[\n",
    "        \"Enhanced feature engineering with polynomial features\",\n",
    "        \"Added Codeweave GPU support for neural networks\", \n",
    "        \"Integrated EMR Spark for big data analytics\",\n",
    "        \"Improved cost optimization with spot instances\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Workflow version created: {version_info.version}\")\n",
    "\n",
    "# Export workflow for sharing\n",
    "workflow_export = cdao_sdk.export_workflow(\n",
    "    workflow=comprehensive_ml_pipeline,\n",
    "    include_dependencies=True,\n",
    "    format=\"yaml\"\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Workflow exported for team collaboration\")\n",
    "\n",
    "print(\"\\nüéØ CDAO SDK Demo Completed Successfully!\")\n",
    "print(\"üîó All tasks executed across optimal compute platforms via Flyte plugins\")\n",
    "print(\"üìä Real-time monitoring and cost optimization enabled\")\n",
    "print(\"üöÄ Ready for production deployment and team collaboration\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
